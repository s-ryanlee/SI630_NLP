{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba09b56-7cda-4217-b56a-273521448363",
   "metadata": {},
   "source": [
    "# Prompt-Based NLP\n",
    "\n",
    "In Homework 4, we’ll try using Jigsaw’s Toxic Language dataset using PET to train our classifier.\n",
    "Conveniently the PET authors have already provided code for you to use at https://github.com/timoschick/pet. Your task will be to (1) write your own custom verbalizer and patterns\n",
    "and (2) train your model by modifying one of their example scripts. The PET repository has good\n",
    "documentation on how to set up their model, train it, and use the code.\n",
    "\n",
    "Like in Homework 3, in this assignment we will use a much smaller but nearly-as-performant\n",
    "version of BERT, https://huggingface.co/microsoft/MiniLM-L12-H384-uncased,\n",
    "to train our models. While PET can work on any LLM, MiniLM will make the homework much\n",
    "faster to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abaf087-6059-4ee5-b3e3-38af01d28d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification #EarlyStoppingCallback\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import wandb\n",
    "import os\n",
    "from pathlib import Path\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f49e127-284c-4158-ac5c-f840dcedd188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156603</th>\n",
       "      <td>d10f0baab32ca062</td>\n",
       "      <td>this page is a complete mess \\n\\nno one seems ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99860</th>\n",
       "      <td>16584c23f714d37f</td>\n",
       "      <td>Suck cock you snivelling cunt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80413</th>\n",
       "      <td>d72132805bb8629b</td>\n",
       "      <td>\"\\n Your submission at AfC Benson Dillon Billi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153083</th>\n",
       "      <td>97260f6f0a501e7c</td>\n",
       "      <td>More vandalism by this IP address \\n\\nSee here.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>27f0dbfcd47c759a</td>\n",
       "      <td>is D's imprisonment really a turning point ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "156603  d10f0baab32ca062  this page is a complete mess \\n\\nno one seems ...   \n",
       "99860   16584c23f714d37f                      Suck cock you snivelling cunt   \n",
       "80413   d72132805bb8629b  \"\\n Your submission at AfC Benson Dillon Billi...   \n",
       "153083  97260f6f0a501e7c    More vandalism by this IP address \\n\\nSee here.   \n",
       "15124   27f0dbfcd47c759a       is D's imprisonment really a turning point ?   \n",
       "\n",
       "        toxic  \n",
       "156603      0  \n",
       "99860       1  \n",
       "80413       0  \n",
       "153083      0  \n",
       "15124       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/hw4_train.csv')\n",
    "test_df = pd.read_csv('data/hw4_test.csv')\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcee123c-39dc-459f-8709-bb3bb61b890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unlabeled data and dev data\n",
    "\n",
    "train_unlabled_df = train_df.drop('toxic', axis=1)\n",
    "train_unlabled_df.to_csv('data/hw4_train_unlabled.csv', index=False)\n",
    "\n",
    "dev_split_pcent = .2\n",
    "dev_split_size = round(train_df.shape[0] * .2)\n",
    "dev_df = train_df.sample(dev_split_size).copy()\n",
    "dev_df.to_csv('data/hw4_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308298c3-c189-44d1-bdbf-75002581f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'microsoft/MiniLM-L12-H384-uncased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c4e7c0-afe9-4d18-8152-5737bf4aec69",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1\n",
    "\n",
    "Write a simple piece code that takes a single word as input and then\n",
    "tokenizes it with the BERT tokenizer in huggingface and returns the word’s corresponding tokens\n",
    "(or token IDs) in the BERT vocabulary. You’ll want to use this piece of code in the next task to\n",
    "check that your verbalizer is using only single-token words.\n",
    "\n",
    "This section only needs to be run once - currently the tokenized data is saved in `data/tokenized_train_dataset.pt` and `data/tokenized_test_dataset.pt` and can be loaded and used after the kernel has been shut down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1171d5-0f6f-450e-9e0b-d191c56c6b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>0ab669a21bd76681</td>\n",
       "      <td>Why is there more information on the Transform...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                       comment_text  \\\n",
       "4007  0ab669a21bd76681  Why is there more information on the Transform...   \n",
       "\n",
       "      toxic  \n",
       "4007      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919ca1f8-2393-4801-97f3-0646309dced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "was a superhero what it appeared to be it was a superhero between and reason why it is a superhero because due to actions in stopping by the law in criminal why it is a superhero\n",
      "-------------------\n",
      "44\n",
      "RoboCop was a superhero \n",
      "\n",
      "What it appeared to be it was a superhero between cyberpunk and action, reason why it is a superhero because due to RoboCop's actions in stopping crime, by upholding the law in criminal charge. That's why it is a superhero\n"
     ]
    }
   ],
   "source": [
    "#debug = Dataset.from_pandas(train_df.sample(5, random_state=630))\n",
    "debug = train_df.sample(5, random_state=630)\n",
    "example = debug['comment_text'].values[0]\n",
    "example_list = example.split()\n",
    "oneword_tokens = []\n",
    "for word in example_list:\n",
    "    token = tokenizer.tokenize(word)\n",
    "    if len(token) == 1:\n",
    "        oneword_tokens.append(token[0])\n",
    "\n",
    "print(len(oneword_tokens))\n",
    "print(' '.join(oneword_tokens))\n",
    "print('-------------------')\n",
    "print(len(example_list))\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a06e49f0-da64-4c4c-a783-c5f5f484b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No padding necessary? \n",
    "\n",
    "def process_data_for_tokenizer(string):\n",
    "    \"\"\"\n",
    "    accepts a string and tokenizes it using a predefined tokenizer (such as BertTokenizer)\n",
    "    checks to see if the length of the list of tokens is one\n",
    "    if the token list is greater than 1, it is dropped\n",
    "    otherwise, it is added to a new list\n",
    "    returns a new string which will be split into single word tokens\n",
    "    \"\"\"\n",
    "    string_list = string.split()\n",
    "    oneword_tokens = []\n",
    "    start_len = len(string_list)\n",
    "    for word in string_list:\n",
    "        token = tokenizer.tokenize(word)\n",
    "        if len(token) == 1:\n",
    "            oneword_tokens.append(token[0])\n",
    "\n",
    "    oneword_string = ' '.join(oneword_tokens)\n",
    "    end_len = len(oneword_string)\n",
    "    if start_len != end_len:\n",
    "        print(\"removed multi-word tokens\")\n",
    "    else:\n",
    "        print(\"no multi-word tokens present\")\n",
    "\n",
    "    return oneword_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c635693-71f9-4755-8dd8-c4e3c9e7d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed multi-word tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'was a superhero what it appeared to be it was a superhero between and reason why it is a superhero because due to actions in stopping by the law in criminal why it is a superhero'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneword_example = process_data_for_tokenizer(example)\n",
    "oneword_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb409f17-afd0-4985-b9a8-01efa309859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed multi-word tokens\n",
      "removed multi-word tokens\n",
      "removed multi-word tokens\n",
      "removed multi-word tokens\n",
      "removed multi-word tokens\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>oneword_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57910</th>\n",
       "      <td>9b113508b15890f7</td>\n",
       "      <td>RoboCop was a superhero \\n\\nWhat it appeared t...</td>\n",
       "      <td>0</td>\n",
       "      <td>was a superhero what it appeared to be it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7231</th>\n",
       "      <td>1342886f4e88377c</td>\n",
       "      <td>Christopher Walken \\nDoesn't this guy look lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>christopher this guy look like christopher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72996</th>\n",
       "      <td>c34aa1b92d69847c</td>\n",
       "      <td>Hmmm... hat we have is perhaps a merge or perh...</td>\n",
       "      <td>0</td>\n",
       "      <td>hat we have is perhaps a merge or perhaps just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48556</th>\n",
       "      <td>81de738eee0c2837</td>\n",
       "      <td>hey shut up ok just because i dont know much e...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey shut up ok just because i know much englis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120561</th>\n",
       "      <td>84f1c010e30b3cd7</td>\n",
       "      <td>Phuck?\\n\\nPhuck Phred Phelps.</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "57910   9b113508b15890f7  RoboCop was a superhero \\n\\nWhat it appeared t...   \n",
       "7231    1342886f4e88377c  Christopher Walken \\nDoesn't this guy look lik...   \n",
       "72996   c34aa1b92d69847c  Hmmm... hat we have is perhaps a merge or perh...   \n",
       "48556   81de738eee0c2837  hey shut up ok just because i dont know much e...   \n",
       "120561  84f1c010e30b3cd7                      Phuck?\\n\\nPhuck Phred Phelps.   \n",
       "\n",
       "        toxic                                   oneword_comments  \n",
       "57910       0  was a superhero what it appeared to be it was ...  \n",
       "7231        0         christopher this guy look like christopher  \n",
       "72996       0  hat we have is perhaps a merge or perhaps just...  \n",
       "48556       1  hey shut up ok just because i know much englis...  \n",
       "120561      0                                                     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug['oneword_comments'] = debug.comment_text.apply(process_data_for_tokenizer)\n",
    "debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44704efa-b62e-421f-8f8d-df2139c25356",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check Verbalizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb74982a-d8a4-40b6-be62-e0efa6f2db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check verbalizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7930f-b2c7-42ce-91d7-60d5c73086cd",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Write 10 different prompts that can be used to classify toxic speech.\n",
    "Prompts should be relatively different (not just adding/changing one word). For each, come up\n",
    "with at least 2 verbalizations of each class (toxic/non-toxic). You can share verbalizations across\n",
    "prompts if needed. We really want to see some creativity across your prompts (this will also help\n",
    "the model learn more too)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba464e-5874-4f31-86fc-df31172c1813",
   "metadata": {},
   "source": [
    "### Initialize MyTaskDataProcessor and MyTaskPVP\n",
    "\n",
    "Both are necessary for completing a Task\n",
    "\n",
    "Initialized in a new file inside `pet/custom` called `toxic_task_processor.py` and `toxic_task_pvp.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3c4e8-8f5c-49d7-8e7a-88190be0daa6",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "For comparison with PET, train a regular classifier using Trainer and\n",
    "the MiniLM parameters on all the training data (very similar to what you did in Homework 3!). You\n",
    "should train your model for at least two epochs, but you’re not required to do any hyperparameter\n",
    "tuning (you just need a score). Predict the toxicity of the provided test data and calculate the F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "311ff5db-3dce-4676-ba18-62c260da7da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MiniLM_tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "MiniLMmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 512\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex for ex in examples[\"comment_text\"]]\n",
    "    model_inputs = tokenizer(inputs, padding='max_length', max_length=max_input_length, truncation=True)\n",
    "\n",
    "\n",
    "    model_inputs[\"labels\"] = examples[\"labels\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d91c8b3-72d5-445c-a3b7-c2691e866b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df.rename(columns={'toxic':'labels'}))\n",
    "# dev_dataset = Dataset.from_pandas(dev_df.rename(columns={'toxic':'labels'}))\n",
    "test_dataset = Dataset.from_pandas(test_df.rename(columns={'toxic':'labels'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c59287b-a3e5-46f8-b49a-c902e2e4e086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'comment_text', 'labels'],\n",
       "    num_rows: 159571\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef67f63c-9a83-4ab9-adfe-456e61726090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'comment_text', 'labels'],\n",
       "    num_rows: 63978\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "931a029b-86cc-40a4-8b46-217b59c4d07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4d5715507f4afb9585547027f69568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159571 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05173e5c230499882a4d775f3b2c73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31914 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a52528447434b079d39cf48a1a1b557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63978 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "#tokenized_dev_dataset = dev_dataset.map(lambda x: tokenizer(x['comment_text'],padding = 'max_length', max_length =512, truncation=True))\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9604933c-5c6e-4c8f-8bf2-56b19fa0de12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'comment_text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 63978\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f1e2233-66e1-4de0-b82f-ad28e7287c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "# tokenized_dev_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "tokenized_test_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a25478-83d5-4878-8e09-12fe7f3fb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    preds = preds.reshape(len(preds),)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    return {\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2331db7-884f-451a-9cf5-d944278d2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep getting errors\n",
    "# __init__() got an unexpected keyword argument 'evaluation_strategy'\n",
    "# __init__() got an unexpected keyword argument 'load_best_model_at_end'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'MiniLM',\n",
    "    num_train_epochs = 2,\n",
    "#    evaluation_strategy = 'steps',\n",
    "#    eval_steps = 500,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 16,\n",
    "#    seed = 0,\n",
    "#    load_best_model_at_end = True,\n",
    "    gradient_accumulation_steps = 16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abfb03b6-3cce-4b5b-96e7-790ff8fe27bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:zh0knd60) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dry-snowflake-35</strong>: <a href=\"https://wandb.ai/s-ryanlee/huggingface/runs/zh0knd60\" target=\"_blank\">https://wandb.ai/s-ryanlee/huggingface/runs/zh0knd60</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220417_112227-zh0knd60/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:zh0knd60). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sryanlee/SI630_hw4/wandb/run-20220417_112230-2unituqu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/s-ryanlee/huggingface/runs/2unituqu\" target=\"_blank\">rosy-snowflake-36</a></strong> to <a href=\"https://wandb.ai/s-ryanlee/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    MiniLMmodel,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "#    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbf544-0829-4913-8865-25e1f17dd929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2748f29dc04e8c96c428293562d543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17289ccd10284d028d507edf364233e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/9974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0418d-6e52-4cb7-82aa-c51c930ae7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('MiniLMmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c647847-b8b3-4cef-8792-9e4d17a5b39a",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "Using your patterns and verbalizers, train separate PET models on 10,\n",
    "50, 100, and 500 instances of data. Your data should be randomly sampled from the training data\n",
    "but be sure to have examples of each class. You are free to choose which instances you use and\n",
    "what distribution of toxic/non-toxic labels are in your training data (provided you have at least one\n",
    "example of each). For each model, predict the scores for the provided test data and calculate the\n",
    "Macro F1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49642039-7e68-4263-9b34-5b226f5fdeb3",
   "metadata": {},
   "source": [
    "### Sample data for each PET instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65746759-087a-440d-a787-a208554c16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('toxic').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66909646-fa31-4f04-8474-898e7607ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [10, 50, 100, 500]\n",
    "if os.path.exists('data/instances') == True:\n",
    "    for instance in instances:\n",
    "        if os.path.exists('data/instances/instance'+str(instance)+'/hw4_train.csv') == False:\n",
    "            instance_train = train_df.groupby('toxic').sample(instance)\n",
    "            instance_train = instance_train[['toxic', 'comment_text', 'id']]\n",
    "            instance_train.to_csv('data/instances/'+'instance'+str(instance)+'/hw4_train.csv', index=False, header=False)\n",
    "        if os.path.exists('data/instances/instance'+str(instance)+'/hw4_train_unlabeled.csv') == False:\n",
    "            instance_train_unlabeled = train_unlabled_df.sample(instance)\n",
    "            instance_train_unlabeled = instance_train_unlabeled[['comment_text', 'id']]\n",
    "            instance_train_unlabled.to_csv('data/instances/'+'instance'+str(instance)+'/hw4_train_unlabeled.csv', index=False, header=False)\n",
    "        if os.path.exists('data/instances/instance'+str(instance)+'/hw4_dev.csv') == False:\n",
    "            instance_dev = train_df.groupby('toxic').sample(instance)\n",
    "            instance_dev = instance_dev[['toxic', 'comment_text', 'id']]\n",
    "            instance_dev.to_csv('data/instances/'+'instance'+str(instance)+'/hw4_dev.csv', index=False, header=False)\n",
    "        if os.path.exists('data/instances/instance'+str(instance)+'/hw4_test.csv') == False:\n",
    "            instance_test = test_df.groupby('toxic').sample(instance)\n",
    "            instance_test = instance_test[['toxic', 'comment_text', 'id']]\n",
    "            instance_test.to_csv('data/instances/'+'instance'+str(instance)+'/hw4_test.csv', index=False, header=False)\n",
    "else:\n",
    "    print(\"create instance data directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e13917-7ee2-4a5d-87e8-7e02e96a51fd",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "Let’s compare our PET-based models and our regular all-data MiniLM\n",
    "model. Plot the score for each PET model and your full-data MiniLM model using Seaborn. If\n",
    "you are feeling curious, feel free to train models on different sizes/distributions of data and include\n",
    "those too. Write your guess on how many instances you think you need to train a PET model that\n",
    "will reach the performance of a MiniLM model trained on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8f9b4-7336-4a52-b4a2-ce6fb1c87e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
