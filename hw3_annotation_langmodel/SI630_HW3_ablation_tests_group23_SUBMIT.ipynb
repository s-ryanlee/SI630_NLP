{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d50c6e",
   "metadata": {},
   "source": [
    "# Annotation Evaluation via Classification\n",
    "\n",
    "Put your trained Large Language Model to use to examine how annotators and guidelines might have influenced the model performance. Specifically, you’ll perform annotator ablation tests where we hold out the annotations of some groups of annotators and see how (1) the model performance changes and (2) in the validation set, whether model predictions\n",
    "are more or less similar to those annotators’ labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f1f779-9b03-4f29-9f8b-245306dfacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, EarlyStoppingCallback\n",
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "import torch\n",
    "import wandb\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368623d8-4fbd-4784-b099-d842b59cec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ablation metrics function\n",
    "def compute_ablation_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    preds = preds.reshape(len(preds),)\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "    return {\n",
    "        'mse': mse\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1616995-fcc5-4190-b7a1-59bfb6412c00",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad5c88d-4aac-4068-809c-5dbdd3fcb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/si630w22-hw3-train.csv')\n",
    "dev_data = pd.read_csv('data/si630w22-hw3-dev.csv')\n",
    "q_and_a_data = pd.read_csv('data/si630w22-hw3-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e32bb9-c211-4af7-a92f-61388b7da1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_and_a_data['text'] = q_and_a_data.question_text + '[SEP]' + q_and_a_data.reply_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0099151-a321-494f-9ae5-7f28b11151bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ablation = train_data.rename(columns={'id':'question_id', 'rating':'labels'})\n",
    "train_data_ablation = pd.merge(train_data_ablation,q_and_a_data[['text','question_id']], on='question_id', how='left')\n",
    "train_data_ablation.dropna(subset=['labels'], inplace = True)\n",
    "\n",
    "dev_data_ablation = dev_data.rename(columns={'id':'question_id', 'rating':'labels'})\n",
    "dev_data_ablation = pd.merge(dev_data_ablation,q_and_a_data[['text','question_id']], on='question_id', how='left')\n",
    "dev_data_ablation.dropna(subset=['labels'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75196a-e7bf-4a0b-ad6c-952874017a50",
   "metadata": {},
   "source": [
    "## Initialize Ablation Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81884b81-c29c-4515-8730-70141076c6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ablation Data Directory Already Exists\n",
      "Ablation Training Directory Already Exists\n",
      "Ablation Saved Model Directory Already Exists\n",
      "Ablation Prediction Directory Already Exists\n"
     ]
    }
   ],
   "source": [
    "# all groups\n",
    "all_groups = train_data_ablation.group.unique()\n",
    "\n",
    "# make ablation_data dirs for all groups\n",
    "ablation_data_dir = Path('./ablation_data/') \n",
    "if ablation_data_dir.exists() == False:\n",
    "    print(\"Creating Ablation Data Directory\")\n",
    "    os.mkdir(ablation_data_dir)\n",
    "    for group_name in all_groups:\n",
    "        group_dir = group_name\n",
    "        group_path = os.path.join(ablation_data_dir, group_dir)\n",
    "        os.mkdir(group_path)\n",
    "else:\n",
    "    print(\"Ablation Data Directory Already Exists\")\n",
    "    \n",
    "# make ablation_training dirs for all groups\n",
    "ablation_training_dir = Path('./ablation_training/') \n",
    "if ablation_training_dir.exists() == False:\n",
    "    print(\"Creating Ablation Training Directory\")\n",
    "    os.mkdir(ablation_training_dir)\n",
    "    for group_name in all_groups:\n",
    "        group_dir = group_name\n",
    "        group_path = os.path.join(ablation_training_dir, group_dir)\n",
    "        os.mkdir(group_path)\n",
    "else:\n",
    "    print(\"Ablation Training Directory Already Exists\")\n",
    "\n",
    "# make ablation_model_save dirs for all groups\n",
    "ablation_model_dir = Path('./ablation_model/') \n",
    "if ablation_model_dir.exists() == False:\n",
    "    print(\"Creating Ablation Saved Model Directory\")\n",
    "    os.mkdir(ablation_model_dir)\n",
    "    for group_name in all_groups:\n",
    "        group_dir = group_name\n",
    "        group_path = os.path.join(ablation_model_dir, group_dir)\n",
    "        os.mkdir(group_path)\n",
    "else:\n",
    "    print(\"Ablation Saved Model Directory Already Exists\")\n",
    "\n",
    "# make ablation_prediction dirs for all groups\n",
    "ablation_predict_dir = Path('./ablation_prediction/') \n",
    "if ablation_predict_dir.exists() == False:\n",
    "    print(\"Creating Ablation Prediction Directory\")\n",
    "    os.mkdir(ablation_predict_dir)\n",
    "    for group_name in all_groups:\n",
    "        group_dir = group_name\n",
    "        group_path = os.path.join(ablation_predict_dir, group_dir)\n",
    "        os.mkdir(group_path)\n",
    "else:\n",
    "    print(\"Ablation Prediction Directory Already Exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7785c-9d5a-461a-bb28-05715c2e8c49",
   "metadata": {},
   "source": [
    "## Initial Debugging Pass\n",
    "\n",
    "Complete Ablation Test Method only on Group 1. Then generalize code to loop through all groups to perform ablation tests.\n",
    "\n",
    "After initial debugging pass was completed without error on `group_01`, the code was copied into a loop and tested on the first three groups in `all_groups`. Then, once this ran without error, the loop was applied to every group in `all_groups`.\n",
    "\n",
    "The method is outlined below, but debugging code was removed.\n",
    "1. Create Group Specific Paths\n",
    "2. Create Train Data\n",
    "3. Create Test Data\n",
    "    - Training\n",
    "        1. remove any question_ids annotated by group 1. This is the first training set\n",
    "        2. group by remaining question_ids (after group 1 ids were removed) and average the rating value - this is the ground truth for training\n",
    "        3. apply the rating value to the question_ids in the training set\n",
    "    - Dev Split A\n",
    "        1. repeat the process used for the training set ground truth labels\n",
    "    - Dev Split B\n",
    "        1. using only group 1 question_ids, average the rating value of group 1 annotators on these question_ids - this is the ground truth for dev split b\n",
    "        2. apply the rating value to the question_ids in the dev split b set\n",
    "    - Dev Split C\n",
    "        1. using only group 1 question_ids, average the rating value of all other groups (excluding group 1) on these question_ids - this is the ground truth for dev split c\n",
    "        2. apply the rating value to the question_ids in the dev split c set\n",
    "    - Repeat this process for every single group\n",
    "        - There will be 3 separate ground truth labels for each of the Dev splits. We then evaluate each dev split (for every group) and calcualate correlation for every group and plot.\n",
    "4. Data Preprocessing\n",
    "    - Data Loading\n",
    "    - Data Tokenizing\n",
    "    - Data Formatting\n",
    "5. Intialize and Train Model\n",
    "6. Make Predictions\n",
    "7. Calculate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5b2dd2-cf38-4887-9dd8-9a0944119a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMATTING DATA\n"
     ]
    }
   ],
   "source": [
    "print('FORMATTING DATA')\n",
    "\n",
    "tokenized_ablation_train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "tokenized_ablation_test_dataset_a.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "tokenized_ablation_test_dataset_b.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "tokenized_ablation_test_dataset_c.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad46328-060b-4cb1-8b08-039f4f5b4767",
   "metadata": {},
   "source": [
    "## Complete Ablation Tests\n",
    "\n",
    "Loop through all groups (23 in total) and complete the ablation test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a0f8381-92b8-4b99-b8e3-088457b90a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/vocab.txt from cache at /home/sryanlee/.cache/huggingface/transformers/49c302ee103bf6737d0877cfbd658563cf4bbc4b7914363ca419ce8a3d8a4c51.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/special_tokens_map.json from cache at /home/sryanlee/.cache/huggingface/transformers/1e5909e4dfaa904617797ed35a6105a23daa56cbefca48fef329f772584699fb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/tokenizer_config.json from cache at /home/sryanlee/.cache/huggingface/transformers/29039dfe8c131360348e9f5ebecd464478cec7576c9af532b55ddcf9d4ec8d1e.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading configuration file https://huggingface.co/microsoft/MiniLM-L12-H384-uncased/resolve/main/config.json from cache at /home/sryanlee/.cache/huggingface/transformers/ceb753d3f27a8c0d09184f35884666cda91b8ae610cd2a54d89793ac7663f1f9.13815020fd994b27db9974c0ce0ec4c47dfac6c8f11bf1a35a0a06d5b165665a\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/MiniLM-L12-H384-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file simple_best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/MiniLM-L12-H384-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file simple_best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at simple_best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# same tokenizer for every group\n",
    "tokenizer = BertTokenizer.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\", padding = True, truncation=True ,max_length =512)\n",
    "\n",
    "# same model and training args for every training.\n",
    "helpfulness_model = BertForSequenceClassification.from_pretrained(\"simple_best_model/\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be2a516d-b1b4-470d-9031-01163cbcf4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING ABLATION: GROUP_09\n",
      "GROUP DATA PATH: ablation_data/group_09\n",
      "GROUP TRAINING PATH: ablation_training/group_09\n",
      "GROUP MODEL PATH: ablation_model/group_09\n",
      "GROUP PREDICT PATH: ablation_prediction/group_09\n",
      "CREATING TRAIN DATA\n",
      "group annotators\n",
      " ['user_00' 'user_01' 'user_02'] \n",
      "\n",
      "Success: Row Drop Match\n",
      "Number of Rows Dropped:  921\n",
      "CREATING TEST DATA\n",
      "Unique Question IDs Mismatch\n",
      "number of unique questions gi annotated: 61\n",
      "number of unique questions annotated by other groups: 59\n",
      "LOADING DATA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2f945a000c4c02c1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-2f945a000c4c02c1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5b8a52349d4cbdbaebbe96cb04ea94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc481a51d1846838a5b29d99a6c8cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-2f945a000c4c02c1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eccbffc99b848febffc4f19b521061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0d8b4fe71d7efd54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-0d8b4fe71d7efd54/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d1d8ab58fa4f9a8f8c9790b90eb997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9409850aece447cd9f83a4af64a6585a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-0d8b4fe71d7efd54/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e304783bdfdf4150b4dbed391f2917fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c8cc3e03efdbbb9d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-c8cc3e03efdbbb9d/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc0dde887be4f48abe6c660fd3ddc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf36491b8274446a14a24f4de2f0915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-c8cc3e03efdbbb9d/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b3700abc2f4a43be6dc986bbb2b1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-299212abaf51852c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-299212abaf51852c/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187687a389ec42d3b1d692664b91265a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c13d8517164f0ba82473d3b74f3105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-299212abaf51852c/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0eece8bcd04a2f93d51298df1e43cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZING DATA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45149c39d4494f9497f9ccc9d45a5b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3768 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388e65c81ee047d48fa13d7eb6e3782e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/809 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139b05ddb39448c8b93f3e6ab0d74a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8831941fc2dc4343ab6da49879120419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/sryanlee/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3768\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1413\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMATTING DATA\n",
      "INITIALIZING MODEL\n",
      "TRAINING MODEL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1413' max='1413' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1413/1413 03:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.522300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.471300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ablation_training/group_09/group_09_model/checkpoint-500\n",
      "Configuration saved in ablation_training/group_09/group_09_model/checkpoint-500/config.json\n",
      "Model weights saved in ablation_training/group_09/group_09_model/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ablation_training/group_09/group_09_model/checkpoint-1000\n",
      "Configuration saved in ablation_training/group_09/group_09_model/checkpoint-1000/config.json\n",
      "Model weights saved in ablation_training/group_09/group_09_model/checkpoint-1000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ablation_model/group_09/group_09_trained_model\n",
      "Configuration saved in ablation_model/group_09/group_09_trained_model/config.json\n",
      "Model weights saved in ablation_model/group_09/group_09_trained_model/pytorch_model.bin\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 809\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKING PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 59\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING ABLATION: GROUP_03\n",
      "GROUP DATA PATH: ablation_data/group_03\n",
      "GROUP TRAINING PATH: ablation_training/group_03\n",
      "GROUP MODEL PATH: ablation_model/group_03\n",
      "GROUP PREDICT PATH: ablation_prediction/group_03\n",
      "CREATING TRAIN DATA\n",
      "group annotators\n",
      " ['user_03' 'user_04'] \n",
      "\n",
      "Success: Row Drop Match\n",
      "Number of Rows Dropped:  620\n",
      "CREATING TEST DATA\n",
      "Unique Question IDs Mismatch\n",
      "number of unique questions gi annotated: 62\n",
      "number of unique questions annotated by other groups: 58\n",
      "LOADING DATA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-83b59bbc8b86e7f2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-83b59bbc8b86e7f2/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f207564aa140b388d5bde17d878593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859df726f12a40e88145eec4fba1b53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-83b59bbc8b86e7f2/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379707e3f2ff42538dd12148898fd963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-177bb2d08c860fca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-177bb2d08c860fca/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819ad260db914ac9a356d84b80319282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8620fdfe4af4cc284c909d043916111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-177bb2d08c860fca/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9b1e7579d642489368d5280701ff40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-f39aff3b7e7ccf5b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-f39aff3b7e7ccf5b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857acdbb68df4e05bc9c34475ad5c21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5593ae593d634c6ea4f29fd008c15d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-f39aff3b7e7ccf5b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f38d9b8bbe48bcacaa42f17fc21c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7ddc81fe127d270a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-7ddc81fe127d270a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469f03384e144d86964660d992068580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db58dd39e8c4c16b9b4dd2bdaded2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-7ddc81fe127d270a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc040438dafd418fb195e8bb65f398ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZING DATA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c4d991b37b44c2b42f0bde47ae93df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3766 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0045ca16f64253af0588c54c6f9ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/807 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02506cc85ba9445d8271abd41e9f13c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e645b55986e247eb85ad42b2b1a600fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/sryanlee/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3766\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1413\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMATTING DATA\n",
      "INITIALIZING MODEL\n",
      "TRAINING MODEL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1413' max='1413' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1413/1413 03:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.451800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ablation_training/group_03/group_03_model/checkpoint-500\n",
      "Configuration saved in ablation_training/group_03/group_03_model/checkpoint-500/config.json\n",
      "Model weights saved in ablation_training/group_03/group_03_model/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ablation_training/group_03/group_03_model/checkpoint-1000\n",
      "Configuration saved in ablation_training/group_03/group_03_model/checkpoint-1000/config.json\n",
      "Model weights saved in ablation_training/group_03/group_03_model/checkpoint-1000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ablation_model/group_03/group_03_trained_model\n",
      "Configuration saved in ablation_model/group_03/group_03_trained_model/config.json\n",
      "Model weights saved in ablation_model/group_03/group_03_trained_model/pytorch_model.bin\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKING PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 62\n",
      "  Batch size = 8\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 58\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING ABLATION: GROUP_10\n",
      "GROUP DATA PATH: ablation_data/group_10\n",
      "GROUP TRAINING PATH: ablation_training/group_10\n",
      "GROUP MODEL PATH: ablation_model/group_10\n",
      "GROUP PREDICT PATH: ablation_prediction/group_10\n",
      "CREATING TRAIN DATA\n",
      "group annotators\n",
      " ['user_05' 'user_06' 'user_07'] \n",
      "\n",
      "Success: Row Drop Match\n",
      "Number of Rows Dropped:  906\n",
      "CREATING TEST DATA\n",
      "Unique Question IDs Mismatch\n",
      "number of unique questions gi annotated: 53\n",
      "number of unique questions annotated by other groups: 52\n",
      "LOADING DATA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6fcf357bb469f29e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-6fcf357bb469f29e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2163eadd5c4909af26bded50ecd30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1896c16f734c4b43bc0f6bfc2468e5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-6fcf357bb469f29e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d84e919603d4279820e8c4d27c2c2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a4a781ad0c424ba0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-a4a781ad0c424ba0/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba2065c898144f6907d82ab9f9b79c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6adfc9a350d48899dec84063490928d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-a4a781ad0c424ba0/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55bcbf92d69453baf5b4f7667bcaa30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c42f67616911e07f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-c42f67616911e07f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dd3c6a42524cc892a769e15b97d0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bb3ebe937745a7aae1012659e8b52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-c42f67616911e07f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c3b26cdf8740f5872cb53d5a936c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1d295a8648d5bca2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sryanlee/.cache/huggingface/datasets/csv/default-1d295a8648d5bca2/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fccd54fa6d543a6881ef4c8f2b11742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9284ecd7604715ada37ba808109fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sryanlee/.cache/huggingface/datasets/csv/default-1d295a8648d5bca2/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d8a935dbd04208b1963b17f0278a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZING DATA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0073e667fc4bfd87b11ba36d315469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3764 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147a8f3984d44811a6f0b4850fcb3c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/810 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4777688b614d439679b8f822ba0a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c0722adb0248e58f602eed92076b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/sryanlee/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3764\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1413\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMATTING DATA\n",
      "INITIALIZING MODEL\n",
      "TRAINING MODEL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1413' max='1413' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1413/1413 03:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.426200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ablation_training/group_10/group_10_model/checkpoint-500\n",
      "Configuration saved in ablation_training/group_10/group_10_model/checkpoint-500/config.json\n",
      "Model weights saved in ablation_training/group_10/group_10_model/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ablation_training/group_10/group_10_model/checkpoint-1000\n",
      "Configuration saved in ablation_training/group_10/group_10_model/checkpoint-1000/config.json\n",
      "Model weights saved in ablation_training/group_10/group_10_model/checkpoint-1000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ablation_model/group_10/group_10_trained_model\n",
      "Configuration saved in ablation_model/group_10/group_10_trained_model/config.json\n",
      "Model weights saved in ablation_model/group_10/group_10_trained_model/pytorch_model.bin\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 810\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAKING PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 53\n",
      "  Batch size = 8\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, question_id, annotator_id, group. If text, question_id, annotator_id, group are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 52\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "all_correlations = []\n",
    "for group_name in all_groups:\n",
    "    \n",
    "    # create group specific paths\n",
    "    group_data_path = os.path.join(ablation_data_dir, group_name)\n",
    "    group_training_path = os.path.join(ablation_training_dir, group_name)\n",
    "    group_model_path = os.path.join(ablation_model_dir, group_name)\n",
    "    group_predict_path = os.path.join(ablation_predict_dir, group_name)\n",
    "\n",
    "    print('STARTING ABLATION:', group_name.upper())\n",
    "    \n",
    "    # remove all annotations by any annotator in g1 from training data\n",
    "    print('CREATING TRAIN DATA')\n",
    "\n",
    "    g_annotators = train_data_ablation[train_data_ablation['group'] == group_name].annotator_id.unique()\n",
    "    g_drop_index = train_data_ablation[train_data_ablation['annotator_id'].isin(g_annotators)].index\n",
    "    g_drop_data = train_data_ablation.drop(g_drop_index)\n",
    "\n",
    "    # create ground truth by averaging scores of remaining annotators\n",
    "    g_truth = g_drop_data.groupby('question_id').mean()\n",
    "    g_drop_data_truth = g_drop_data.merge(g_truth, on='question_id', how='left').drop(columns='labels_x').rename(columns={'labels_y':'labels'}).drop_duplicates(subset='question_id')\n",
    "    g_drop_data_truth.to_csv(os.path.join(group_data_path, group_name+'_train.csv'), index=False)\n",
    "    \n",
    "    # split dev data into 3 test sets \n",
    "    print('CREATING TEST DATA')\n",
    "    g_qdev_index = dev_data_ablation[dev_data_ablation['annotator_id'].isin(g_annotators)].index\n",
    "\n",
    "    # replies without any annotators in g\n",
    "    g_dev_a = dev_data_ablation.drop(g_qdev_index)\n",
    "    g_truth_a = g_dev_a.groupby('question_id').mean()\n",
    "    g_dev_a_truth = g_dev_a.merge(g_truth_a, on='question_id', how='left').drop(columns='labels_x').rename(columns={'labels_y':'labels'}).drop_duplicates(subset='question_id')\n",
    "    g_dev_a_truth.to_csv(os.path.join(group_data_path, group_name+'_dev_a.csv'), index=False)\n",
    "\n",
    "    # replies to items with annotators in g1 and using their annotations\n",
    "    g_dev_b = dev_data_ablation.loc[g_qdev_index]\n",
    "    g_truth_b = g_dev_b.groupby('question_id').mean()\n",
    "    g_dev_b_truth = g_dev_b.merge(g_truth_b, on='question_id', how='left').drop(columns='labels_x').rename(columns={'labels_y':'labels'}).drop_duplicates(subset='question_id')\n",
    "    g_dev_b_truth.to_csv(os.path.join(group_data_path, group_name+'_dev_b.csv'), index=False)\n",
    "\n",
    "    # the same replies as b but using the annotations by the individuals not in g1\n",
    "    g_qids = g_dev_b.question_id.unique()\n",
    "    g_dev_c = g_dev_a[g_dev_a['question_id'].isin(g_qids)].copy()\n",
    "    g_truth_c = g_dev_c.groupby('question_id').mean()\n",
    "    g_dev_c_truth = g_dev_c.merge(g_truth_c, on='question_id', how='left').drop(columns='labels_x').rename(columns={'labels_y':'labels'}).drop_duplicates(subset='question_id')\n",
    "    g_dev_c_truth.to_csv(os.path.join(group_data_path, group_name+'_dev_c.csv'), index=False)\n",
    "    \n",
    "    # data preprocessing - data loading\n",
    "    print('LOADING DATA')\n",
    "    ablation_train_dataset = load_dataset(\"csv\", data_files={\"train\": os.path.join(group_data_path, group_name+'_train.csv')})\n",
    "    ablation_test_dataset_a = load_dataset('csv', data_files={\"test\": os.path.join(group_data_path, group_name+'_dev_a.csv')})\n",
    "    ablation_test_dataset_b = load_dataset('csv', data_files={\"test\": os.path.join(group_data_path, group_name+'_dev_b.csv')})\n",
    "    ablation_test_dataset_c = load_dataset('csv', data_files={\"test\": os.path.join(group_data_path, group_name+'_dev_c.csv')})\n",
    "    \n",
    "    # data preprocessing - tokenization\n",
    "    print('TOKENIZING DATA')\n",
    "    tokenized_ablation_train_dataset = ablation_train_dataset['train'].map(lambda x: tokenizer(x['text'],padding = 'max_length', max_length =512, truncation=True))\n",
    "    tokenized_ablation_test_dataset_a = ablation_test_dataset_a['test'].map(lambda x: tokenizer(x['text'],padding = 'max_length', max_length =512, truncation=True))\n",
    "    tokenized_ablation_test_dataset_b = ablation_test_dataset_b['test'].map(lambda x: tokenizer(x['text'],padding = 'max_length', max_length =512, truncation=True))\n",
    "    tokenized_ablation_test_dataset_c = ablation_test_dataset_c['test'].map(lambda x: tokenizer(x['text'],padding = 'max_length', max_length =512, truncation=True))\n",
    "    \n",
    "    # data preprocessing - formatting\n",
    "    print('FORMATTING DATA')\n",
    "\n",
    "    tokenized_ablation_train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "    tokenized_ablation_test_dataset_a.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "    tokenized_ablation_test_dataset_b.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "    tokenized_ablation_test_dataset_c.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask','labels'])\n",
    "    \n",
    "    # initialize TrainingArguments, Trainer classes, model (simple_best_model) defined globally\n",
    "    print('INITIALIZING MODEL')\n",
    "\n",
    "    group_output_dir = os.path.join(group_training_path, group_name+'_model/')\n",
    "    \n",
    "    ablation_training_args = TrainingArguments(\n",
    "        output_dir = group_output_dir, \n",
    "        num_train_epochs = 3,\n",
    "        eval_steps = 500,\n",
    "        learning_rate=1e-4,\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 8,\n",
    "        seed = 0,\n",
    "    )\n",
    "    \n",
    "    ablation_trainer = Trainer(\n",
    "        helpfulness_model,\n",
    "        ablation_training_args,\n",
    "        train_dataset=tokenized_ablation_train_dataset,\n",
    "        compute_metrics=compute_ablation_metrics,\n",
    "    )\n",
    "    \n",
    "    # train the model on the ablation group\n",
    "    print('TRAINING MODEL')\n",
    "    ablation_trainer.train()\n",
    "    ablation_trainer.save_model(os.path.join(group_model_path, group_name+'_trained_model'))\n",
    "    \n",
    "    # use 3 dev sets as test sets and evaluate them all separately\n",
    "    print('MAKING PREDICTIONS')\n",
    "\n",
    "    outputs_a = ablation_trainer.predict(tokenized_ablation_test_dataset_a)\n",
    "    y_pred_a = outputs_a.predictions\n",
    "    g_dev_a_truth['predicted'] = y_pred_a\n",
    "    g_dev_a_truth['ablation_group'] = group_name\n",
    "    g_dev_a_truth['subset'] = 'a'\n",
    "    g_dev_a_truth['mse'] = mean_squared_error(g_dev_a_truth.labels, g_dev_a_truth.predicted)\n",
    "\n",
    "    outputs_b = ablation_trainer.predict(tokenized_ablation_test_dataset_b)\n",
    "    y_pred_b = outputs_b.predictions\n",
    "    g_dev_b_truth['predicted'] = y_pred_b\n",
    "    g_dev_b_truth['ablation_group'] = group_name\n",
    "    g_dev_b_truth['subset'] = 'b'\n",
    "    g_dev_b_truth['mse'] = mean_squared_error(g_dev_b_truth.labels, g_dev_b_truth.predicted)\n",
    "\n",
    "    outputs_c = ablation_trainer.predict(tokenized_ablation_test_dataset_c)\n",
    "    y_pred_c = outputs_c.predictions\n",
    "    g_dev_c_truth['predicted'] = y_pred_c\n",
    "    g_dev_c_truth['ablation_group'] = group_name\n",
    "    g_dev_c_truth['subset'] = 'c'\n",
    "    g_dev_c_truth['mse'] = mean_squared_error(g_dev_c_truth.labels, g_dev_c_truth.predicted)\n",
    "    \n",
    "    # combine predictions\n",
    "    group_predictions = pd.concat([g_dev_a_truth, g_dev_b_truth, g_dev_c_truth], axis=0)\n",
    "    group_predictions.to_csv(os.path.join(group_predict_path, group_name+'_predictions_combined.csv'), index=False)\n",
    "    \n",
    "    # calculate correlation\n",
    "    group_correlations = group_predictions.drop(['question_id','annotator_id', 'group', 'mse'], axis=1).groupby(['ablation_group', 'subset']).corr()\n",
    "    group_correlations_long = group_correlations.drop('labels', axis=1).reset_index().drop('level_2', axis=1).drop_duplicates(subset='subset').rename(columns={'predicted':'correlation'})\n",
    "    all_correlations.append(group_correlations_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b300b059-76ab-467e-8ff7-c9f0db5258aa",
   "metadata": {},
   "source": [
    "## Combine Ablation Results\n",
    "\n",
    "Pull predictions from every ablation group. Combine into one dataframe with new field `ablation group`. Calculate correlations and plot into a bar graph where each group has a set of 3 bars, one for each dev split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7cea339-2caa-46b8-82ac-e371f4280558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='ablation_group', ylabel='correlation'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concat all correlations and then plot\n",
    "all_correlations_df = pd.concat(all_correlations, axis=0)\n",
    "sns.barplot(data=all_correlations_df, x='ablation_group', y='correlation', hue='subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906a5f3-ec86-4e4f-b893-5e3b8f8251d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
